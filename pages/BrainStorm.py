# -*- coding: utf-8 -*-
"""two_agent_debate_tools.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10u2il320xYKL3vLNPnhOfQ9E4caTZ249

# Agent Debates with Tools

This example shows how to simulate multi-agent dialogues where agents have access to tools.

## Import LangChain related modules
"""
import streamlit as st
from typing import Callable, List
#from streamlit import st
from langchain.memory import ConversationBufferMemory
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage,
)
from langchain.chat_models import ChatOpenAI
#from langchain_google_vertexai import ChatVertexAI
from langchain import OpenAI
#from util.functions.Can2TextEng import Sph2Tex

## Import modules related to tools"""

from langchain.agents import AgentType, initialize_agent, load_tools

def discuss():
    """## `DialogueAgent` and `DialogueSimulator` classes
    We will use the same `DialogueAgent` and `DialogueSimulator` classes defined in [Multi-Player Authoritarian Speaker Selection](https://python.langchain.com/en/latest/use_cases/agent_simulations/multiagent_authoritarian.html).
    """
    class DialogueAgent:
        def __init__(
            self,
            name: str,
            system_message: SystemMessage,
            model: ChatOpenAI,
        ) -> None:
            self.name = name
            self.system_message = system_message
            self.model = model
            self.prefix = f"{self.name}: "
            self.reset()

        def reset(self):
            self.message_history = ["Here is the conversation so far."]

        def send(self) -> str:
            """
            Applies the chatmodel to the message history
            and returns the message string
            """
            message = self.model(
                [
                    self.system_message,
                    HumanMessage(content="\n".join(self.message_history + [self.prefix])),
                ]
            )
            return message.content

        def receive(self, name: str, message: str) -> None:
            """
            Concatenates {message} spoken by {name} into message history
            """
            self.message_history.append(f"{name}: {message}")


    class DialogueSimulator:
        def __init__(
            self,
            agents: List[DialogueAgent],
            selection_function: Callable[[int, List[DialogueAgent]], int],
        ) -> None:
            self.agents = agents
            self._step = 0
            self.select_next_speaker = selection_function

        def reset(self):
            for agent in self.agents:
                agent.reset()

        def inject(self, name: str, message: str):
            """
            Initiates the conversation with a {message} from {name}
            """
            for agent in self.agents:
                agent.receive(name, message)

            # increment time
            self._step += 1

        def step(self) -> tuple[str, str]:
            # 1. choose the next speaker
            speaker_idx = self.select_next_speaker(self._step, self.agents)
            speaker = self.agents[speaker_idx]

            # 2. next speaker sends message
            message = speaker.send()

            # 3. everyone receives message
            for receiver in self.agents:
                receiver.receive(speaker.name, message)

            # 4. increment time
            self._step += 1

            return speaker.name, message



    class DialogueAgentWithTools(DialogueAgent):
    
        """
        ## `DialogueAgentWithTools` class
        We define a `DialogueAgentWithTools` class that augment `DialogueAgent` to use tools.
        """
        def __init__(
            self,
            name: str,
            system_message: SystemMessage,
            model: OpenAI(model="gpt-3.5-turbo-instruct"),
            tool_names: List[str],
            **tool_kwargs,
        ) -> None:
            super().__init__(name, system_message, model)
            self.tools = load_tools(tool_names, **tool_kwargs)

        def send(self) -> str:
            """
            Applies the chatmodel to the message history
            and returns the message string
            """
            agent_chain = initialize_agent(
                self.tools,
                self.model,
                agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,
                verbose=True,
                memory=ConversationBufferMemory(
                    memory_key="chat_history", return_messages=True
                ),
            )
            message = AIMessage(
                content=agent_chain.run(
                    input="\n".join(
                        [self.system_message.content] + self.message_history + [self.prefix]
                    )
                )
            )

            return message.content

    def generate_system_message(name, description, tools):
        return f"""{conversation_description}
        
            Name: {name}.

            Description is as follows: {description}

            Goal is to persuade the conversation partner of a typical "{name}" point of view.

            Look up information with the {tools} to refute the partner's claims.
            Save cited sources.
            Not fabricate fake citations.
            Not cite any source that "{name}" did not look up.
            Not add anything else.

            Stop speaking the moment when finish speaking from a typical "{name}" perspective.
            """
    def select_next_speaker(step: int, agents: List[DialogueAgent]) -> int:
        idx = (step) % len(agents)
        return idx
    
    
    
    st.title("Brainstorm with or by AI")
    st.markdown("##### :green[(Quality of the brainstorm depends on which LLM & tools are used)]")
    st.markdown("#### :purple[Subscriptive personal AI services with memory can interact with human]")
    
    """### Define the topic"""
    
    names = {
        "Europe Human Resource Managment Experts": ["arxiv", "ddg-search", "wikipedia"],
        "Professors of Labour Economics in US top 100 universities": ["arxiv", "ddg-search", "wikipedia"],
    }
    
    #on = st.toggle('Activate audio in')

    #if on:
        #st.write('üó£Ô∏è activated!')
        #topic = Sph2Tex()
    
    #else:
    topic = []
    topic = st.text_input(":rainbow[Discussion Topic: Example: Base on corporate culture, such as open mind, transparency what kinds of graduate fit your company? üëá]", key = 401)
   
    word_limit = 40  # word limit for task brainstorming
    
    col_left, col_right = st.columns([0.5,0.5])
    
    password = col_left.text_input(":red[Enter a password ü§ê, GPT3.5 pwd = NoFreeLunch ]", type="password", key = 402)
    
    if topic is not None:
    
        conversation_description = f"""Topic of conversation: {topic};
        AI role-play participants are: {', '.join(names.keys())}"""
    
        add_content = col_right.text_input(":green[Add detail features of the participant üßë‚Äçüéì]", key = 403)
        if add_content is not None:
            agent_descriptor_system_message = SystemMessage(content = add_content)
            #for name, description in agent_descriptions.items():
                #st.write(description)
            
        def generate_agent_description(name):
            agent_specifier_prompt = [
                agent_descriptor_system_message,
                HumanMessage(
                    content=f"""{conversation_description}
                    Please reply with a creative description of {name}, in {word_limit} words or less.
                    Speak directly to {name}.
                    Give them a point of view.
                    Do not add anything else."""
                ),
            ]
            agent_description = ChatOpenAI(model="gpt-3.5-turbo-0125", temperature=1.0)(agent_specifier_prompt).content
            return agent_description
        
        agent_descriptions = {name: generate_agent_description(name) for name in names}

        agent_system_messages = {
            name: generate_system_message(name, description, tools)
            for (name, tools), description in zip(names.items(), agent_descriptions.values())
            }
        
    if password == "NoFreeLunch":
    
        """#### Generate system messages"""
        for name, system_message in agent_system_messages.items():
            #st.write(name)
            st.write(system_message)
            
        topic_specifier_prompt = [
            SystemMessage(content="You can make a topic more specific."),
            HumanMessage(
                content=f"""{topic}
                You are the moderator.
                Please make the topic more specific.
                Please reply with the specified quest in {word_limit} words or less.
                Speak directly to the participants: {*names,}.
                Do not add anything else."""
            ),
        ]
        specified_topic = ChatOpenAI(temperature=1.0)(topic_specifier_prompt).content
        #st.write(f"Original topic:\n{topic}\n")
        st.write(f"Detailed topic:\n{specified_topic}\n")

        """## Main Loop"""

        # we set `top_k_results`=2 as part of the `tool_kwargs` to prevent results from overflowing the context limit
        agents = [
            DialogueAgentWithTools(
                name=name,
                system_message=SystemMessage(content=system_message),
                model=ChatOpenAI(model_name="gpt-3.5-turbo-0125", temperature=0.2),
                tool_names=tools,
                top_k_results=2,
            )
            for (name, tools), system_message in zip(
                names.items(), agent_system_messages.values()
            )
        ]
        max_iters = 6
        n = 0

        simulator = DialogueSimulator(agents=agents, selection_function=select_next_speaker)
        simulator.reset()
        simulator.inject("Moderator", specified_topic)
        st.write(f"(Moderator): {specified_topic}")
        st.write("\n")

        while n < max_iters:
            name, message = simulator.step()
            
            st.write(f"({name}): {message}")
            st.write("\n")
            n += 1

if __name__ == "__main__":
   discuss()
